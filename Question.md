# 问题

## Q1 从3.27求w和b，为什么不能直接让它的导数等于0来求？

你说的方法是解析法，但是实际问题很复杂，很难求得精确解，所以一般要用数值法（拟牛顿法等）来求近似解。

Q2 1.为什么推导logistic回归时需要用到极大似然法，推导最小二乘解时却不需要？在什么情况下需要用到极大似然？2.牛顿迭代二阶导，为啥是对βT求导？

逻辑回归是统计学的角度，用样本估计总体分布的参数，所以用最大似然。最小二乘法，是从数学分析的角度来求解的。完全两个不同的解决问题的途径。 牛顿迭代只是那种数学公式形式，对转置求导，也是对其中的变量求导啊，与是否转置没太大关系啊，不必太纠结。

Q3 代码里的 y_train = df_train[‘class’] - 1 是什么意思？这里为什么要这样做?

为了让类别从0开始计数

Q4 对于线性不可分的数据，为什么用核方法升维在SVM上可以起到很好的效果，而在LR上很容易出现过拟合？

个人觉得 svm有一定的软间隔，即安全距离，所以泛化能力强一些。仅供参考，没有理论支撑。

Q5 能不能解释下判别式模型和生成式模型，何种属于判别式模型，何种属于生成式模型？

判别模型就是直接建模，直接建立一个判别的拟合函数，生成模型就是间接建模计算。这属于文字的概念，影响不大。

Q6 请问5人组队参加相比单人参加有哪些具体优势吗？然后如果是多人参加应该怎么分工比较好

每个人用自己的方法做到最好成绩，然后5个模型进行融合，成绩应该会有提高。融合就是5个人的分类结果，少数服从多数。

Q7 请问只有一般的Windows笔记本电脑￼但是想学linux该怎么办…因为以后总是要用到是装虚拟机还是双系统￼还是换电脑

ubuntu18.04用refuns做个启动盘安装，里面有选择双系统并存，非常简单。

Q8 我看有人说做机器学习或深度学习最好用linux系统，就算mac系统也要比windows好用。是真的吗

当然用linux啊，很多代码都是在linux下进行开发的，只不过初学者先windows入手，但在这个比赛中来讲，没啥区别

Q9 lg = LogisticRegression(C=4, dual=True) 里dual参数的用处是什么？

目标函数转换成对偶函数，易于优化

Q10 我现在做了一些特征，就是文章的长度，怎么和两个特征结合啊，他们的类型不一样啊

可以尝试着把各个特征都归一化

Q11 对于数据集严重偏斜的问题，除了smote，ensemble这些方法以外，还有什么处理技巧？在上述方法无效的情况下，如何处理数据？

一般就是上下采样/不同类别赋予不同的权重/ensemble.先验分布主要就是以部分样本估计总体分布的思想，所以是估计

Q12 做lstm，如果要用batch normalization，那输入数据的预处理，是否可以直接让bn做就行？还是说仍然要注意输入数据处理后的分布？

cnn里面也有bn，但是仍然需要做预处理，所以我的个人建议是预处理仍然要做，bn会重新normalize，然后学一个新的分布，所以最坏的情况只是多做了一个normalize

Q13 那个l1正择化和l2有什么本质的区别吗

当然本质区别了，l1可以让一些变量等于0，l2可以让一些变量趋向0

## Q1:泛化能力是什么
机器学习算法对新鲜样本的适应能力
